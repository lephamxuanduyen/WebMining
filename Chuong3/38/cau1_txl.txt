artificial intelligence ai intelligence machines software opposed intelligence humans animals also field study computer science develops studies intelligent machines ai may also refer machines ai technology widely used throughout industry government science highprofile applications advanced web search engines eg google search recommendation systems used youtube amazon netflix understanding human speech siri alexa selfdriving cars eg waymo generative creative tools chatgpt ai art competing highest level strategic games chess go artificial intelligence founded academic discipline field went multiple cycles optimism followed disappointment loss funding deep learning surpassed previous ai techniques vast increase funding interest various subfields ai research centered around particular goals use particular tools traditional goals ai research include reasoning knowledge representation planning learning natural language processing perception support roboticsa general intelligence ability solve arbitrary problem among fields longterm goals solve problems ai researchers adapted integrated wide range problemsolving techniques including search mathematical optimization formal logic artificial neural networks methods based statistics operations research economicsb ai also draws upon psychology linguistics philosophy neuroscience many fields general problem simulating creating intelligence broken subproblems consist particular traits capabilities researchers expect intelligent system display traits described received attention cover scope ai researcha early researchers developed algorithms imitated stepbystep reasoning humans use solve puzzles make logical deductions late methods developed dealing uncertain incomplete information employing concepts probability economics many algorithms insufficient solving large reasoning problems experience combinatorial explosion became exponentially slower problems grew larger even humans rarely use stepbystep deduction early ai research could model solve problems using fast intuitive judgments accurate efficient reasoning unsolved problem knowledge representation knowledge engineering allow ai programs answer questions intelligently make deductions realworld facts formal knowledge representations used contentbased indexing retrieval scene interpretation clinical decision support knowledge discovery mining interesting actionable inferences large databases areas knowledge base body knowledge represented form used program ontology set objects relations concepts properties used particular domain knowledge knowledge bases need represent things objects properties categories relations objects situations events states time causes effects knowledge knowledge know people know default reasoning things humans assume true told differently remain true even facts changing many aspects domains knowledge among difficult problems kr breadth commonsense knowledge set atomic facts average person knows enormous subsymbolic form commonsense knowledge much people know represented facts statements could express verbally knowledge acquisition difficult problem obtaining knowledge ai applicationsc modern ai gathers knowledge scraping internet including wikipedia knowledge collected volunteers professionals published information may may agreed provide work ai companies crowd sourced technique guarantee knowledge correct reliable knowledge large language models chatgpt highly unreliable generates misinformation falsehoods known hallucinations providing accurate knowledge modern ai applications unsolved problem agent anything perceives takes actions world rational agent goals preferences takes actions make happend automated planning agent specific goal automated decision making agent preferences situations would prefer situations trying avoid decision making agent assigns number situation called utility measures much agent prefers possible action calculate expected utility utility possible outcomes action weighted probability outcome occur choose action maximum expected utility classical planning agent knows exactly effect action realworld problems however agent may certain situation unknown unobservable may know certain happen possible action deterministic must choose action making probabilistic guess reassess situation see action worked problems agents preferences may uncertain especially agents humans involved learned eg inverse reinforcement learning agent seek information improve preferences information value theory used weigh value exploratory experimental actions space possible future actions situations typically intractably large agents must take actions evaluate situations uncertain outcome markov decision process transition model describes probability particular action change state particular way reward function supplies utility state cost action policy associates decision possible state policy could calculated eg iteration heuristic learned game theory describes rational behavior multiple interacting agents used ai programs make decisions involve agents machine learning study programs improve performance given task automatically part ai beginninge several kinds machine learning unsupervised learning analyzes stream data finds patterns makes predictions without guidance supervised learning requires human label input data first comes two main varieties classification program must learn predict category input belongs regression program must deduce numeric function based numeric input reinforcement learning agent rewarded good responses punished bad ones agent learns choose responses classified good transfer learning knowledge gained one problem applied new problem deep learning uses artificial neural networks types learning computational learning theory assess learners computational complexity sample complexity much data required notions optimization natural language processing nlp allows programs read write communicate human languages english specific problems include speech recognition speech synthesis machine translation information extraction information retrieval question answering early work based noam chomskys generative grammar semantic networks difficulty wordsense disambiguationf unless restricted small domains called microworlds due common sense knowledge problem modern deep learning techniques nlp include word embedding often one word appears near another transformers finds patterns text others generative pretrained transformer gpt language models began generate coherent text models able get humanlevel scores bar exam sat gre many realworld applications machine perception ability use input sensors cameras microphones wireless signals active lidar sonar radar tactile sensors deduce aspects world computer vision ability analyze visual input field includes speech recognition image classification facial recognition object recognition robotic perception robotics uses ai affective computing interdisciplinary umbrella comprises systems recognize interpret process simulate human feeling emotion mood example virtual assistants programmed speak conversationally even banter humorously makes appear sensitive emotional dynamics human interaction otherwise facilitate humancomputer interaction however tends give naïve users unrealistic conception intelligent existing computer agents actually moderate successes related affective computing include textual sentiment analysis recently multimodal sentiment analysis wherein ai classifies affects displayed videotaped subject machine artificial general intelligence able solve wide variety problems breadth versatility similar human intelligence ai research uses wide variety tools accomplish goals aboveb ai solve many problems intelligently searching many possible solutions two different kinds search used ai state space search local search state space search searches tree possible states try find goal state example planning algorithms search trees goals subgoals attempting find path target goal process called meansends analysis simple exhaustive searches rarely sufficient realworld problems search space number places search quickly grows astronomical numbers result search slow never completes heuristics rules thumb help prioritize choices likely reach goal adversarial search used gameplaying programs chess go searches tree possible moves countermoves looking winning position local search uses mathematical optimization find numeric solution problem begins form guess refines guess incrementally refinements made algorithms visualized blind hill climbing begin search random point landscape jumps steps keep moving guess uphill reach top process called stochastic gradient descent evolutionary computation uses form optimization search example may begin population organisms guesses allow mutate recombine selecting fittest survive generation refining guesses distributed search processes coordinate via swarm intelligence algorithms two popular swarm algorithms used search particle swarm optimization inspired bird flocking ant colony optimization inspired ant trails neural networks statistical classifiers discussed also use form local search landscape searched formed learning formal logic used reasoning knowledge representation formal logic comes two main forms propositional logic operates statements true false uses logical connectives implies predicate logic also operates objects predicates relations uses quantifiers every x xs ys logical inference deduction process proving new statement conclusion statements already known true premises logical knowledge base also handles queries assertions special case inference inference rule describes valid step proof general inference rule resolution inference reduced performing search find path leads premises conclusions step application inference rule inference performed way intractable except short proofs restricted domains efficient powerful general method discovered fuzzy logic assigns degree truth handles uncertainty probabilistic situations nonmonotonic logics designed handle default reasoning specialized versions logic developed describe many complex domains see knowledge representation many problems ai including reasoning planning learning perception robotics require agent operate incomplete uncertain information ai researchers devised number tools solve problems using methods probability theory economics bayesian networks general tool used many problems including reasoning using bayesian inference algorithmg learning using expectationmaximization algorithmh planning using decision networks perception using dynamic bayesian networks probabilistic algorithms also used filtering prediction smoothing finding explanations streams data helping perception systems analyze processes occur time eg hidden markov models kalman filters precise mathematical tools developed analyze agent make choices plan using decision theory decision analysis information value theory tools include models markov decision processes dynamic decision networks game theory mechanism design simplest ai applications divided two types classifiers eg shiny diamond one hand controllers eg diamond pick hand classifiers functions use pattern matching determine closest match finetuned based chosen examples using supervised learning pattern also called observation labeled certain predefined class observations combined class labels known data set new observation received observation classified based previous experience many kinds classifiers use decision tree simplest widely used symbolic machine learning algorithm knearest neighbor algorithm widely used analogical ai mid kernel methods support vector machine svm displaced knearest neighbor naive bayes classifier reportedly widely used learner google due part scalability neural networks also used classifiers artificial neural networks inspired design human brain simple neuron n accepts input neurons activated fired casts weighted vote whether neuron n activate practice input neurons list numbers weights matrix next layer dot product ie several weighted sums scaled increasing function logistic function resemblance real neural cells structures superficial according russell norvig learning algorithms neural networks use local search choose weights get right output input training common training technique backpropagation algorithm neural networks learn model complex relationships inputs outputs find patterns data theory neural network learn function feedforward neural networks signal passes one direction recurrent neural networks feed output signal back input allows shortterm memories previous input events long short term memory successful network architecture recurrent networks perceptrons use single layer neurons deep learning uses multiple layers convolutional neural networks strengthen connection neurons close especially important image processing local set neurons must identify edge network identify object deep learning uses several layers neurons networks inputs outputs multiple layers progressively extract higherlevel features raw input example image processing lower layers may identify edges higher layers may identify concepts relevant human digits letters faces deep learning drastically improved performance programs many important subfields artificial intelligence including computer vision speech recognition image classification others reason deep learning performs well many applications known sudden success deep learning occur new discovery theoretical breakthrough deep neural networks backpropagation described many people far back sj two factors incredible increase computer power including hundredfold increase speed switching gpus availability vast amounts training data especially giant curated datasets used benchmark testing imagenetk late graphics processing units gpus increasingly designed aispecific enhancements used specialized tensorflow software replaced previously used central processing unit cpus dominant means largescale commercial academic machine learning models training historically specialized languages lisp prolog others used ai machine learning technology used essential applications including search engines google search targeting online advertisements recommendation systems offered netflix youtube amazon driving internet traffic targeted advertising adsense facebook virtual assistants siri alexa autonomous vehicles including drones adas selfdriving cars automatic language translation microsoft translator google translate facial recognition apples face id microsofts deepface image labeling used facebook apples iphoto tiktok also thousands successful ai applications used solve specific problems specific industries institutions survey one five companies reported incorporated ai offerings processes examples energy storage medical diagnosis military logistics applications predict result judicial decisions foreign policy supply chain management game playing programs used since demonstrate test ais advanced techniques deep blue became first computer chessplaying system beat reigning world chess champion garry kasparov may jeopardy quiz show exhibition match ibms question answering system watson defeated two greatest jeopardy champions brad rutter ken jennings significant margin march alphago games go match go champion lee sedol becoming first computer goplaying system beat professional go player without handicaps defeated ke jie time continuously held world ranking two years programs handle imperfectinformation games poker superhuman level pluribusl cepheus deepmind developed generalized artificial intelligence could learn many diverse atari games early generative ai gained widespread prominence chatgpt based gpt large language models tried americans adults increasing realism easeofuse aibased texttoimage generators midjourney dalle stable diffusion sparked trend viral aigenerated photos widespread attention gained fake photo pope francis wearing white puffer coat fictional arrest donald trump hoax attack pentagon well usage professional creative arts alphafold demonstrated ability approximate hours rather months structure protein ai like powerful technology potential benefits potential risks ai may able advance science find solutions serious problems demis hassabis deep mind hopes solve intelligence use solve everything else however use ai become widespread several unintended consequences risks identified machine learning applications biased learn biased data developers may aware bias exists bias introduced way training data selected way model deployed biased algorithm used make decisions seriously harm people medicine finance recruitment housing policing algorithm may cause discrimination fairness machine learning study prevent harm caused algorithmic bias become serious area academic study within ai researchers discovered always possible define fairness way satisfies stakeholders june google photoss new image labeling feature mistakenly identified jacky alcine friend gorillas black system trained dataset contained images black people problem called sample size disparity google fixed problem preventing system labelling anything gorilla eight years later google photos still could identify gorilla neither could similar products apple facebook microsoft amazon compas commercial program widely used us courts assess likelihood defendant becoming recidivist julia angwin propublica discovered compas exhibited racial bias despite fact program told races defendants although error rate whites blacks calibrated equal exactly errors race different system consistently overestimated chance black person would reoffend would underestimate chance white person would reoffend several researchersm showed mathematically impossible compas accommodate possible measures fairness base rates reoffense different whites blacks data program make biased decisions even data explicitly mention problematic feature race gender feature correlate features like address shopping history first name program make decisions based features would race gender moritz hardt said robust fact research area fairness blindness doesnt work criticism compas highlighted deeper problem misuse ai machine learning models designed make predictions valid assume future resemble past trained data includes results racist decisions past machine learning models must predict racist decisions made future unfortunately applications uses predictions recommendations recommendations likely racist thus machine learning well suited help make decisions areas hope future better past necessarily descriptive proscriptiven bias unfairness may go undetected developers overwhelmingly white male among ai engineers black women conference fairness accountability transparency acm facct association computing machinery seoul south korea presented published findings recommending ai robotics systems demonstrated free bias mistakes unsafe use selflearning neural networks trained vast unregulated sources flawed internet data curtailed modern ai applications explain reached decision large amount relationships inputs outputs deep neural networks resulting complexity makes difficult even expert explain produced outputs making black box many cases machine learning program passed rigorous tests nevertheless learned something different programmers intended example justin ko roberto novoa developed system could identify skin diseases better medical professionals however classified image ruler cancerous pictures malignancies typically include ruler show scale dangerous example discovered rich caruana machine learning system accurately predicted risk death classified patient asthma difficulty breathing low risk research showed highrisk cases like hospital would allocate resources save patients life decreasing risk measured program mistakes like become obvious know program reached decision without explanation problems may discovered caused harm second issue people harmed algorithms decision right explanation doctors example required clearly completely explain reasoning behind decision make early drafts european unions general data protection regulation included explicit statement right existso industry experts noted unsolved problem solution sight regulators argued nevertheless harm real problem solution tools used darpa established xai explainable artificial intelligence program try solve problems several potential solutions transparency problem multitask learning provides large number outputs addition target classification outputs help developers deduce network learned deconvolution deepdream generative methods allow developers see different layers deep network learned produce output suggest network learning supersparse linear integer models use learning identify important features rather classification simple addition features make classification ie learning used create scoring system classifier transparent lethal autonomous weapon machine locates selects engages human targets without human supervisionp fifty countries reported researching battlefield robots weapons considered especially dangerous several reasons kill innocent person clear held accountable unlikely reliably choose targets produced scale potentially weapons mass destruction nations including china supported ban autonomous weapons united nations convention certain conventional weapons however united states others disagreed ai provides number tools particularly useful authoritarian governments smart spyware face recognition voice recognition allow widespread surveillance surveillance allows machine learning classify potential enemies state prevent hiding recommendation systems precisely target propaganda misinformation maximum effect deepfakes aid producing misinformation advanced ai make authoritarian centralized decision making competitive liberal decentralized systems markets terrorists criminals rogue states use weaponized ai advanced digital warfare lethal autonomous weapons machinelearning ai also able design tens thousands toxic molecules matter hours early days development artificial intelligence arguments example put forward weizenbaum whether tasks done computers actually done given difference computers humans quantitative calculation qualitative valuebased judgement economists frequently highlighted risks redundancies ai speculated unemployment adequate social policy full employment past technology tended increase rather reduce total employment economists acknowledge uncharted territory ai survey economists showed disagreement whether increasing use robots ai cause substantial increase longterm unemployment generally agree could net benefit productivity gains redistributed risk estimates vary example michael osborne carl benedikt frey estimated us jobs high risk potential automation oecd report classified us jobs high riskq methodology speculating future employment levels criticised lacking evidential foundation implying technology rather social policy creates unemployment opposed redundancies unlike previous waves automation many middleclass jobs may eliminated artificial intelligence economist stated worry ai could whitecollar jobs steam power bluecollar ones industrial revolution worth taking seriously jobs extreme risk range paralegals fast food cooks job demand likely increase carerelated professions ranging personal healthcare clergy april reported jobs chinese video game illlustrators eliminated generative artificial intelligence order leverage large dataset feasible generative ai often trained unlicensed copyrighted works including domains images computer code output used rationale fair use experts disagree well circumstances rationale hold courts law relevant factors may include purpose character use copyrighted work effect upon potential market copyrighted work friendly ai machines designed beginning minimize risks make choices benefit humans eliezer yudkowsky coined term argues developing friendly ai higher research priority may require large investment must completed ai becomes existential risk machines intelligence potential use intelligence make ethical decisions field machine ethics provides machines ethical principles procedures resolving ethical dilemmas field machine ethics also called computational morality founded aaai symposium approaches include wendell wallachs artificial moral agents stuart j russells three principles developing provably beneficial machines regulation artificial intelligence development public sector policies laws promoting regulating artificial intelligence ai therefore related broader regulation algorithms regulatory policy landscape ai emerging issue jurisdictions globally according ai index stanford annual number airelated laws passed survey countries jumped one passed passed alone countries adopted dedicated strategies ai eu member states released national ai strategies canada china india japan mauritius russian federation saudi arabia united arab emirates us vietnam others process elaborating ai strategy including bangladesh malaysia tunisia global partnership artificial intelligence launched june stating need ai developed accordance human rights democratic values ensure public confidence trust technology henry kissinger eric schmidt daniel huttenlocher published joint statement november calling government commission regulate ai openai leaders published recommendations governance superintelligence believe may happen less years ipsos survey attitudes towards ai varied greatly country chinese citizens americans agreed products services using ai benefits drawbacks reutersipsos poll found americans agree disagree ai poses risks humanity fox news poll americans thought important additional thought somewhat important federal government regulate ai versus responding important responding important study mechanical formal reasoning began philosophers mathematicians antiquity study logic led directly alan turings theory computation suggested machine shuffling symbols simple could simulate mathematical deduction formal reasoning known churchturing thesis along concurrent discoveries cybernetics information theory led researchers consider possibility building electronic brainr first paper later recognized ai mccullouch pitts design turingcomplete artificial neurons field ai research founded workshop dartmouth college attendees became leaders ai research st students produced programs press described astonishingu computers learning checkers strategies solving word problems algebra proving logical theorems speaking englishv middle research us heavily funded department defense laboratories established around world herbert simon predicted machines capable within twenty years work man marvin minsky agreed writing within generation problem creating artificial intelligence substantially solved however underestimated difficulty problemw us british governments cut exploratory research response criticism sir james lighthill ongoing pressure us congress fund productive projects minskys paperts book perceptrons understood proving artificial neural networks approach would never useful solving realworld tasks thus discrediting approach altogether ai winter period obtaining funding ai projects difficult followed early ai research revived commercial success expert systems form ai program simulated knowledge analytical skills human experts market ai reached billion dollars time japans fifth generation computer project inspired us british governments restore funding academic research however beginning collapse lisp machine market ai fell disrepute second longerlasting winter began many researchers began doubt current practices would able imitate processes human cognition especially perception robotics learning pattern recognition number researchers began look subsymbolic approaches robotics researchers rodney brooks rejected representation general focussed directly engineering machines move survivex judea pearl lofti zadeh others developed methods handled incomplete uncertain information making reasonable guesses rather precise logic important development revival connectionism including neural network research geoffrey hinton others yann lecun successfully showed convolutional neural networks recognize handwritten digits first many successful applications neural networks ai gradually restored reputation late early st century exploiting formal mathematical methods finding specific solutions specific problems narrow formal focus allowed researchers produce verifiable results collaborate fields statistics economics mathematics solutions developed ai researchers widely used although rarely described artificial intelligence several academic researchers became concerned ai longer pursuing original goal creating versatile fully intelligent machines beginning around founded subfield artificial general intelligence agi several wellfunded institutions deep learning began dominate industry benchmarks adopted throughout field many specific tasks methods abandonedy deep learnings success based hardware improvements faster computers graphics processing units cloud computing access large amounts data including curated datasets imagenet deep learnings success led enormous increase interest funding aiz amount machine learning research measured total publications increased years wipo reported ai prolific emerging technology terms number patent applications granted patents according ai impacts billion annually invested ai around us alone new us computer science phd graduates specialized ai airelated us job openings existed issues fairness misuse technology catapulted center stage machine learning conferences publications vastly increased funding became available many researchers refocussed careers issues alignment problem became serious field academic study alan turing wrote propose consider question machines think advised changing question whether machine thinks whether possible machinery show intelligent behaviour devised turing test measures ability machine simulate human conversation since observe behavior machine matter actually thinking literally mind turing notes determine things peopleaa usual polite convention everyone thinks russell norvig agree turing ai must defined terms acting thinking however critical test compares machines people aeronautical engineering texts wrote define goal field making machines fly exactly like pigeons fool pigeons ai founder john mccarthy agreed writing artificial intelligence definition simulation human intelligence mccarthy defines intelligence computational part ability achieve goals world another ai founder marvin minsky similarly defines ability solve hard problems definitions view intelligence terms welldefined problems welldefined solutions difficulty problem performance program direct measures intelligence machineand philosophical discussion required may even possible another definition adopted google better source needed major practitioner field ai definition stipulates ability systems synthesize information manifestation intelligence similar way defined biological intelligence established unifying theory paradigm guided ai research historyab unprecedented success statistical machine learning eclipsed approaches much sources especially business world use term artificial intelligence mean machine learning neural networks approach mostly subsymbolic soft narrow see critics argue questions may revisited future generations ai researchers symbolic ai gofai simulated highlevel conscious reasoning people use solve puzzles express legal reasoning mathematics highly successful intelligent tasks algebra iq tests newell simon proposed physical symbol systems hypothesis physical symbol system necessary sufficient means general intelligent action however symbolic approach failed many tasks humans solve easily learning recognizing object commonsense reasoning moravecs paradox discovery highlevel intelligent tasks easy ai low level instinctive tasks extremely difficult philosopher hubert dreyfus argued since human expertise depends unconscious instinct rather conscious symbol manipulation feel situation rather explicit symbolic knowledge although arguments ridiculed ignored first presented eventually ai research came agreeac issue resolved subsymbolic reasoning make many inscrutable mistakes human intuition algorithmic bias critics noam chomsky argue continuing research symbolic ai still necessary attain general intelligence part subsymbolic ai move away explainable ai difficult impossible understand modern statistical ai program made particular decision emerging field neurosymbolic artificial intelligence attempts bridge two approaches neats hope intelligent behavior described using simple elegant principles logic optimization neural networks scruffies expect necessarily requires solving large number unrelated problems neats defend programs theoretical rigor scruffies rely mainly incremental testing see work issue actively discussed eventually seen irrelevant modern ai elements finding provably correct optimal solution intractable many important problems soft computing set techniques including genetic algorithms fuzzy logic neural networks tolerant imprecision uncertainty partial truth approximation soft computing introduced late successful ai programs st century examples soft computing neural networks ai researchers divided whether pursue goals artificial general intelligence superintelligence directly solve many specific problems possible narrow ai hopes solutions lead indirectly fields longterm goals general intelligence difficult define difficult measure modern ai verifiable successes focusing specific problems specific solutions experimental subfield artificial general intelligence studies area exclusively philosophy mind know whether machine mind consciousness mental states sense human beings issue considers internal experiences machine rather external behavior mainstream ai research considers issue irrelevant affect goals field build machines solve problems using intelligence russell norvig add additional project making machine conscious exactly way humans one equipped take however question become central philosophy mind also typically central question issue artificial intelligence fiction david chalmers identified two problems understanding mind named hard easy problems consciousness easy problem understanding brain processes signals makes plans controls behavior hard problem explaining feels feel like anything assuming right thinking truly feel like something dennetts consciousness illusionism says illusion human information processing easy explain however human subjective experience difficult explain example easy imagine colorblind person learned identify objects field view red clear would required person know red looks like computationalism position philosophy mind human mind information processing system thinking form computing computationalism argues relationship mind body similar identical relationship software hardware thus may solution mindbody problem philosophical position inspired work ai researchers cognitive scientists originally proposed philosophers jerry fodor hilary putnam philosopher john searle characterized position strong ai appropriately programmed computer right inputs outputs would thereby mind exactly sense human beings mindsad searle counters assertion chinese room argument attempts show even machine perfectly simulates human behavior still reason suppose also mind machine mind subjective experience may also sentience ability feel could also suffer argued could entitle certain rights hypothetical robot rights would lie spectrum animal rights human rights issue considered fiction centuries considered example californias institute future however critics argue discussion premature superintelligence hypothetical agent would possess intelligence far surpassing brightest gifted human mind research artificial general intelligence produced sufficiently intelligent software might able reprogram improve improved software would even better improving leading j good called intelligence explosion vernor vinge called singularity however technologies improve exponentially indefinitely rather follow scurve slowing reach physical limits technology consider example transportation experienced exponential improvement trend abruptly stopped reached physical limits argued ai become powerful humanity may irreversibly lose control could physicist stephen hawking puts spell end human race scenario common science fiction computer robot suddenly develops humanlike selfawareness sentience consciousness becomes malevolent characterae scifi scenarios misleading several ways first ai require humanlike sentience existential risk modern ai programs given specific goals use learning intelligence achieve philosopher nick bostrom argued one gives almost goal sufficiently powerful ai may choose destroy humanity achieve used example paperclip factory manager stuart russell gives example household robot tries find way kill owner prevent unplugged reasoning cant fetch coffee youre dead order safe humanity superintelligence would genuinely aligned humanitys morality values fundamentally side second yuval noah harari argues ai require robot body physical control pose existential risk essential parts civilization physical things like ideologies law government money economy made language exist stories billions people believe current prevalence misinformation suggests ai could use language convince people believe anything even take actions destructive opinions amongst experts industry insiders mixed sizable fractions concerned unconcerned risk eventual superintelligent ai personalities stephen hawking bill gates elon musk expressed concern existential risk ai early experts argued risks distant future warrant research humans valuable perspective superintelligent machine however study current future risks possible solutions became serious area research ai pioneers including geoffrey hinton yoshua bengio demis hassabis sam altman issued joint statement mitigating risk extinction ai global priority alongside societalscale risks pandemics nuclear war others yann lecun consider unfounded robot designer hans moravec cyberneticist kevin warwick inventor ray kurzweil predicted humans machines merge future cyborgs capable powerful either idea called transhumanism roots aldous huxley robert ettinger edward fredkin argues artificial intelligence next stage evolution idea first proposed samuel butlers darwin among machines far back expanded upon george dyson book name thoughtcapable artificial beings appeared storytelling devices since antiquity persistent theme science fiction common trope works began mary shelleys frankenstein human creation becomes threat masters includes works arthur c clarkes stanley kubricks space odyssey hal murderous computer charge discovery one spaceship well terminator matrix contrast rare loyal robots gort day earth stood still bishop aliens less prominent popular culture isaac asimov introduced three laws robotics many books stories notably multivac series superintelligent computer name asimovs laws often brought lay discussions machine ethics almost artificial intelligence researchers familiar asimovs laws popular culture generally consider laws useless many reasons one ambiguity several works use ai force us confront fundamental question makes us human showing us artificial beings ability feel thus suffer appears karel čapeks rur films ai artificial intelligence ex machina well novel androids dream electric sheep philip k dick dick considers idea understanding human subjectivity altered technology created artificial intelligence two widely used textbooks see open syllabus four widely used ai textbooks later editions 